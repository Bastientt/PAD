# üõ°Ô∏è PAD - Presence & Liveness Detection

**PAD** est un syst√®me de s√©curit√© biom√©trique con√ßu pour v√©rifier la pr√©sence r√©elle d'un utilisateur (Liveness Detection). Il utilise une analyse de pose de t√™te en 3D pour valider des d√©fis de mouvements al√©atoires (ex: GAUCHE, HAUT, BAS), emp√™chant ainsi les fraudes par photo ou vid√©o pr√©-enregistr√©e.



---

## üèóÔ∏è Architecture Technique

Le projet est d√©coup√© en micro-services orchestr√©s par Docker :

* **Frontend** : Interface utilisateur pour la capture vid√©o.
* **Backend (Rust)** : API haute performance (Actix-web) g√©rant les sessions, les d√©fis et la communication asynchrone via Redis.
* **IA_Worker (Python)** : Moteur d'analyse bas√© sur **MediaPipe** et **OpenCV**. Il estime la rotation de la t√™te en degr√©s r√©els via l'algorithme `solvePnP`.
* **Infrastructure** :
    * **Redis** : Bus de messages (Pub/Sub) pour la distribution des jobs d'analyse.
    * **MinIO** : Stockage S3-compatible pour les vid√©os temporaires avant analyse.

---

## üß† Comment marche l'IA ?

L'analyse ne repose pas sur une simple reconnaissance d'image, mais sur une reconstruction g√©om√©trique du visage :

### 1. Extraction des Landmarks
Le worker utilise MediaPipe Face Mesh pour extraire 468 points de rep√®re faciaux en 3D. Pour le calcul de pose, nous isolons 6 points critiques : le bout du nez, le menton, les coins externes des yeux et les coins de la bouche.

### 2. Estimation de Pose 3D (SolvePnP)
L'algorithme `solvePnP` (Perspective-n-Point) compare ces points 2D extraits de l'image avec un mod√®le de visage 3D g√©n√©rique. Cette m√©thode permet de calculer une matrice de rotation et de s'affranchir des distorsions li√©es √† la distance entre l'utilisateur et son t√©l√©phone.

### 3. Conversion en Angles d'Euler
La matrice de rotation est convertie en degr√©s r√©els pour obtenir le **Yaw** (rotation gauche/droite) et le **Pitch** (inclinaison haut/bas) :
* **Yaw** : $\arctan2(R_{0,2}, R_{2,2})$
* **Pitch** : $\arcsin(-R_{1,2})$



### 4. Validation par Hyst√©r√©sis
Pour garantir une d√©tection robuste, le worker utilise une machine √† √©tats √† double seuil :
* **D√©tection** : Le mouvement est valid√© si l'angle d√©passe un seuil (ex: 20¬∞) pendant plusieurs frames cons√©cutives.
* **Retour au Neutre** : L'√©tape suivante du d√©fi ne se d√©bloque que si l'utilisateur revient dans une zone centrale (zone de s√©curit√©), emp√™chant ainsi les validations multiples d'un m√™me mouvement.

---

## üì° API Endpoints (Backend Rust)

L'API communique avec le frontend et d√©l√®gue l'analyse lourde au worker via Redis.

| M√©thode | Endpoint | Description |
| :--- | :--- | :--- |
| `GET` | `/challenge/new` | G√©n√®re une s√©quence al√©atoire (ex: `GAUCHE,HAUT`) et un `user_id` temporaire. |
| `POST` | `/video/upload` | Re√ßoit le fichier `.mp4`/`.webm`. Upload la vid√©o sur MinIO et publie un job dans la queue Redis `ia_jobs`. |
| `GET` | `/result/{user_id}` | V√©rifie le statut de l'analyse (Polling ou via WebSocket). |

### Exemple de payload de retour (Redis `ia_results`) :
```json
{
  "user_id": "8708301549686279141",
  "status": "IA_SUCCESS",
  "filename": "video_123.mp4",
  "details": "S√©quence d√©tect√©e: ['GAUCHE', 'HAUT']"
}